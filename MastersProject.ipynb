{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2582,
     "status": "ok",
     "timestamp": 1689624100162,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "bFBRtueF5TFK"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1689624100163,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "qdDI2BiZYRO7"
   },
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X = data[\"data\"]\n",
    "y = [[t] for t in data[\"target\"]]\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False).fit(y)\n",
    "y = ohe.transform(y)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1689624100163,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "PsGaNpbjZQoY"
   },
   "outputs": [],
   "source": [
    "xtr, xts, ytr, yts = train_test_split(X, y, train_size=0.7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1689624100163,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "Ba6Fw5YlZSqW"
   },
   "outputs": [],
   "source": [
    "class ClassicDense(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super().__init__()\n",
    "        input, output = layer_sizes[0], layer_sizes[-1]\n",
    "        self.hidden = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(layer_sizes[i], layer_sizes[i + 1])\n",
    "                for i in range(len(layer_sizes) - 2)\n",
    "            ]\n",
    "        )\n",
    "        self.act = nn.ModuleList([nn.ReLU() for i in range(len(layer_sizes) - 2)])\n",
    "        self.output = nn.Linear(layer_sizes[-2], layer_sizes[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for hidden, act in zip(self.hidden, self.act):\n",
    "            x = act(hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1689624100164,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "Dmc03rnoZY2m"
   },
   "outputs": [],
   "source": [
    "def get_batched(data, batch_size):\n",
    "    if batch_size is None:\n",
    "        return data\n",
    "    dc = deepcopy(data)\n",
    "    while dc.numel():\n",
    "        batch, dc = dc[:batch_size], dc[batch_size:]\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def format_stats(loss, acc):\n",
    "    return f\"Loss={loss:.2f}, Accuracy={acc*100:.1f}%\"\n",
    "\n",
    "\n",
    "def train(model, xtr, ytr, batch_size=None):\n",
    "    cum_loss, cum_acc = [], []\n",
    "    for xtrb, ytrb in zip(get_batched(xtr, batch_size), get_batched(ytr, batch_size)):\n",
    "        ypred = model(xtrb)\n",
    "        loss = loss_fn(ypred, ytrb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = (torch.argmax(ypred, 1) == torch.argmax(ytrb, 1)).float().mean()\n",
    "        cum_loss.append(float(loss))\n",
    "        cum_acc.append(float(acc))\n",
    "    return cum_loss, cum_acc\n",
    "\n",
    "\n",
    "def test(model, xts, yts):\n",
    "    ypred = model(xts)\n",
    "    loss = loss_fn(ypred, yts)\n",
    "    acc = (torch.argmax(ypred, 1) == torch.argmax(xts, 1)).float().mean()\n",
    "    return float(loss), float(acc)\n",
    "\n",
    "\n",
    "def train_epochs(\n",
    "    model, xtr, ytr, xts=None, yts=None, n_epochs=100, batch_size=5, verbose=False\n",
    "):\n",
    "    best_acc = -np.inf\n",
    "    best_weights = None\n",
    "    train_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    test_loss_hist = []\n",
    "    test_acc_hist = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        cum_loss, cum_acc = train(model, xtr, ytr, batch_size)\n",
    "        model.eval()\n",
    "        mloss, macc = np.mean(cum_loss), np.mean(cum_acc)\n",
    "        train_loss_hist.append(mloss)\n",
    "        train_acc_hist.append(macc)\n",
    "\n",
    "        if all(x is not None for x in (xts, yts)):\n",
    "            mloss, macc = test(model, xts, yts)\n",
    "\n",
    "        if macc > best_acc:\n",
    "            best_acc = macc\n",
    "            best_weights = deepcopy(model.state_dict())\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch} validation: {format_stats(mloss, macc)}\")\n",
    "    if verbose:\n",
    "        print(f\"Best validation: {format_stats(mloss, macc)}\")\n",
    "    model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28911,
     "status": "ok",
     "timestamp": 1689624129897,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "FL7SQMQHX7uV",
    "outputId": "73259caf-dbc9-4530-d44b-9e5d3820d427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassicDense(\n",
      "  (hidden): ModuleList(\n",
      "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "  )\n",
      "  (act): ModuleList(\n",
      "    (0): ReLU()\n",
      "  )\n",
      "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n",
      "Loss=1.18, Accuracy=93.3% Loss=1.03, Accuracy=35.6%\n",
      "ClassicDense(\n",
      "  (hidden): ModuleList(\n",
      "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (1): Linear(in_features=8, out_features=8, bias=True)\n",
      "  )\n",
      "  (act): ModuleList(\n",
      "    (0-1): 2 x ReLU()\n",
      "  )\n",
      "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n",
      "Loss=1.06, Accuracy=0.0% Loss=0.91, Accuracy=35.6%\n",
      "ClassicDense(\n",
      "  (hidden): ModuleList(\n",
      "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (1): Linear(in_features=8, out_features=16, bias=True)\n",
      "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (act): ModuleList(\n",
      "    (0-2): 3 x ReLU()\n",
      "  )\n",
      "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n",
      "Loss=1.10, Accuracy=100.0% Loss=1.07, Accuracy=100.0%\n"
     ]
    }
   ],
   "source": [
    "model = ClassicDense(layer_sizes=[4, 8, 3])\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "pre_loss, pre_acc = test(model, xts, yts)\n",
    "train_epochs(model, xtr, ytr, xts, yts)\n",
    "post_loss, post_acc = test(model, xts, yts)\n",
    "print(format_stats(pre_loss, pre_acc), format_stats(post_loss, post_acc))\n",
    "\n",
    "model = ClassicDense(layer_sizes=[4, 8, 8, 3])\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "pre_loss, pre_acc = test(model, xts, yts)\n",
    "train_epochs(model, xtr, ytr, xts, yts)\n",
    "post_loss, post_acc = test(model, xts, yts)\n",
    "print(format_stats(pre_loss, pre_acc), format_stats(post_loss, post_acc))\n",
    "\n",
    "model = ClassicDense(layer_sizes=[4, 8, 16, 8, 3])\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "pre_loss, pre_acc = test(model, xts, yts)\n",
    "train_epochs(model, xtr, ytr, xts, yts)\n",
    "post_loss, post_acc = test(model, xts, yts)\n",
    "print(format_stats(pre_loss, pre_acc), format_stats(post_loss, post_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1689622710529,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "TIqG-m9ULYQi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassicDense(\n",
      "  (hidden): ModuleList(\n",
      "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (1): Linear(in_features=8, out_features=8, bias=True)\n",
      "  )\n",
      "  (act): ModuleList(\n",
      "    (0-1): 2 x ReLU()\n",
      "  )\n",
      "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n",
      "Epoch 0 validation: Loss=1.10, Accuracy=0.0%\n",
      "Epoch 1 validation: Loss=1.08, Accuracy=0.0%\n",
      "Epoch 2 validation: Loss=1.06, Accuracy=0.0%\n",
      "Epoch 3 validation: Loss=1.04, Accuracy=0.0%\n",
      "Epoch 4 validation: Loss=1.02, Accuracy=0.0%\n",
      "Epoch 5 validation: Loss=1.00, Accuracy=0.0%\n",
      "Epoch 6 validation: Loss=0.98, Accuracy=0.0%\n",
      "Epoch 7 validation: Loss=0.96, Accuracy=0.0%\n",
      "Epoch 8 validation: Loss=0.94, Accuracy=0.0%\n",
      "Epoch 9 validation: Loss=0.93, Accuracy=0.0%\n",
      "Epoch 10 validation: Loss=0.91, Accuracy=0.0%\n",
      "Epoch 11 validation: Loss=0.90, Accuracy=0.0%\n",
      "Epoch 12 validation: Loss=0.88, Accuracy=0.0%\n",
      "Epoch 13 validation: Loss=0.87, Accuracy=0.0%\n",
      "Epoch 14 validation: Loss=0.86, Accuracy=0.0%\n",
      "Epoch 15 validation: Loss=0.85, Accuracy=0.0%\n",
      "Epoch 16 validation: Loss=0.84, Accuracy=0.0%\n",
      "Epoch 17 validation: Loss=0.82, Accuracy=0.0%\n",
      "Epoch 18 validation: Loss=0.78, Accuracy=35.6%\n",
      "Epoch 19 validation: Loss=0.71, Accuracy=35.6%\n",
      "Epoch 20 validation: Loss=0.64, Accuracy=35.6%\n",
      "Epoch 21 validation: Loss=0.57, Accuracy=35.6%\n",
      "Epoch 22 validation: Loss=0.52, Accuracy=35.6%\n",
      "Epoch 23 validation: Loss=0.48, Accuracy=35.6%\n",
      "Epoch 24 validation: Loss=0.45, Accuracy=35.6%\n",
      "Epoch 25 validation: Loss=0.43, Accuracy=35.6%\n",
      "Epoch 26 validation: Loss=0.41, Accuracy=35.6%\n",
      "Epoch 27 validation: Loss=0.39, Accuracy=35.6%\n",
      "Epoch 28 validation: Loss=0.38, Accuracy=35.6%\n",
      "Epoch 29 validation: Loss=0.36, Accuracy=35.6%\n",
      "Epoch 30 validation: Loss=0.35, Accuracy=35.6%\n",
      "Epoch 31 validation: Loss=0.34, Accuracy=35.6%\n",
      "Epoch 32 validation: Loss=0.33, Accuracy=35.6%\n",
      "Epoch 33 validation: Loss=0.32, Accuracy=35.6%\n",
      "Epoch 34 validation: Loss=0.31, Accuracy=35.6%\n",
      "Epoch 35 validation: Loss=0.30, Accuracy=35.6%\n",
      "Epoch 36 validation: Loss=0.29, Accuracy=35.6%\n",
      "Epoch 37 validation: Loss=0.29, Accuracy=35.6%\n",
      "Epoch 38 validation: Loss=0.28, Accuracy=35.6%\n",
      "Epoch 39 validation: Loss=0.27, Accuracy=35.6%\n",
      "Epoch 40 validation: Loss=0.26, Accuracy=35.6%\n",
      "Epoch 41 validation: Loss=0.25, Accuracy=35.6%\n",
      "Epoch 42 validation: Loss=0.25, Accuracy=35.6%\n",
      "Epoch 43 validation: Loss=0.24, Accuracy=35.6%\n",
      "Epoch 44 validation: Loss=0.23, Accuracy=35.6%\n",
      "Epoch 45 validation: Loss=0.23, Accuracy=35.6%\n",
      "Epoch 46 validation: Loss=0.22, Accuracy=35.6%\n",
      "Epoch 47 validation: Loss=0.21, Accuracy=35.6%\n",
      "Epoch 48 validation: Loss=0.21, Accuracy=35.6%\n",
      "Epoch 49 validation: Loss=0.20, Accuracy=35.6%\n",
      "Epoch 50 validation: Loss=0.20, Accuracy=35.6%\n",
      "Epoch 51 validation: Loss=0.19, Accuracy=35.6%\n",
      "Epoch 52 validation: Loss=0.19, Accuracy=35.6%\n",
      "Epoch 53 validation: Loss=0.18, Accuracy=35.6%\n",
      "Epoch 54 validation: Loss=0.18, Accuracy=35.6%\n",
      "Epoch 55 validation: Loss=0.17, Accuracy=35.6%\n",
      "Epoch 56 validation: Loss=0.17, Accuracy=35.6%\n",
      "Epoch 57 validation: Loss=0.16, Accuracy=35.6%\n",
      "Epoch 58 validation: Loss=0.16, Accuracy=35.6%\n",
      "Epoch 59 validation: Loss=0.16, Accuracy=35.6%\n",
      "Epoch 60 validation: Loss=0.15, Accuracy=35.6%\n",
      "Epoch 61 validation: Loss=0.15, Accuracy=35.6%\n",
      "Epoch 62 validation: Loss=0.15, Accuracy=35.6%\n",
      "Epoch 63 validation: Loss=0.14, Accuracy=35.6%\n",
      "Epoch 64 validation: Loss=0.14, Accuracy=35.6%\n",
      "Epoch 65 validation: Loss=0.14, Accuracy=35.6%\n",
      "Epoch 66 validation: Loss=0.13, Accuracy=35.6%\n",
      "Epoch 67 validation: Loss=0.13, Accuracy=35.6%\n",
      "Epoch 68 validation: Loss=0.13, Accuracy=35.6%\n",
      "Epoch 69 validation: Loss=0.12, Accuracy=35.6%\n",
      "Epoch 70 validation: Loss=0.12, Accuracy=35.6%\n",
      "Epoch 71 validation: Loss=0.12, Accuracy=35.6%\n",
      "Epoch 72 validation: Loss=0.12, Accuracy=35.6%\n",
      "Epoch 73 validation: Loss=0.11, Accuracy=35.6%\n",
      "Epoch 74 validation: Loss=0.11, Accuracy=35.6%\n",
      "Epoch 75 validation: Loss=0.11, Accuracy=35.6%\n",
      "Epoch 76 validation: Loss=0.11, Accuracy=35.6%\n",
      "Epoch 77 validation: Loss=0.11, Accuracy=35.6%\n",
      "Epoch 78 validation: Loss=0.10, Accuracy=35.6%\n",
      "Epoch 79 validation: Loss=0.10, Accuracy=35.6%\n",
      "Epoch 80 validation: Loss=0.10, Accuracy=35.6%\n",
      "Epoch 81 validation: Loss=0.10, Accuracy=35.6%\n",
      "Epoch 82 validation: Loss=0.10, Accuracy=35.6%\n",
      "Epoch 83 validation: Loss=0.10, Accuracy=35.6%\n",
      "Epoch 84 validation: Loss=0.09, Accuracy=35.6%\n",
      "Epoch 85 validation: Loss=0.09, Accuracy=35.6%\n",
      "Epoch 86 validation: Loss=0.09, Accuracy=35.6%\n",
      "Epoch 87 validation: Loss=0.09, Accuracy=35.6%\n",
      "Epoch 88 validation: Loss=0.09, Accuracy=35.6%\n",
      "Epoch 89 validation: Loss=0.09, Accuracy=35.6%\n",
      "Epoch 90 validation: Loss=0.09, Accuracy=35.6%\n",
      "Epoch 91 validation: Loss=0.08, Accuracy=35.6%\n",
      "Epoch 92 validation: Loss=0.08, Accuracy=35.6%\n",
      "Epoch 93 validation: Loss=0.08, Accuracy=35.6%\n",
      "Epoch 94 validation: Loss=0.08, Accuracy=35.6%\n",
      "Epoch 95 validation: Loss=0.08, Accuracy=35.6%\n",
      "Epoch 96 validation: Loss=0.08, Accuracy=35.6%\n",
      "Epoch 97 validation: Loss=0.08, Accuracy=35.6%\n",
      "Epoch 98 validation: Loss=0.08, Accuracy=35.6%\n",
      "Epoch 99 validation: Loss=0.08, Accuracy=35.6%\n",
      "Epoch 100 validation: Loss=0.07, Accuracy=35.6%\n",
      "Epoch 101 validation: Loss=0.07, Accuracy=35.6%\n",
      "Epoch 102 validation: Loss=0.07, Accuracy=35.6%\n",
      "Epoch 103 validation: Loss=0.07, Accuracy=35.6%\n",
      "Epoch 104 validation: Loss=0.07, Accuracy=35.6%\n",
      "Epoch 105 validation: Loss=0.07, Accuracy=35.6%\n",
      "Epoch 106 validation: Loss=0.07, Accuracy=35.6%\n",
      "Epoch 107 validation: Loss=0.07, Accuracy=35.6%\n",
      "Epoch 108 validation: Loss=0.07, Accuracy=35.6%\n",
      "Epoch 109 validation: Loss=0.07, Accuracy=35.6%\n",
      "Epoch 110 validation: Loss=0.07, Accuracy=35.6%\n",
      "Epoch 111 validation: Loss=0.07, Accuracy=35.6%\n",
      "Epoch 112 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 113 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 114 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 115 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 116 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 117 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 118 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 119 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 120 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 121 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 122 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 123 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 124 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 125 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 126 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 127 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 128 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 129 validation: Loss=0.06, Accuracy=35.6%\n",
      "Epoch 130 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 131 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 132 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 133 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 134 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 135 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 136 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 137 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 138 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 139 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 140 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 141 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 142 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 143 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 144 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 145 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 146 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 147 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 148 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 149 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 150 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 151 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 152 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 153 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 154 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 155 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 156 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 157 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 158 validation: Loss=0.05, Accuracy=35.6%\n",
      "Epoch 159 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 160 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 161 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 162 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 163 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 164 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 165 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 166 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 167 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 168 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 169 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 170 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 171 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 172 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 173 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 174 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 175 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 176 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 177 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 178 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 179 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 180 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 181 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 182 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 183 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 184 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 185 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 186 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 187 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 188 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 189 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 190 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 191 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 192 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 193 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 194 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 195 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 196 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 197 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 198 validation: Loss=0.04, Accuracy=35.6%\n",
      "Epoch 199 validation: Loss=0.04, Accuracy=35.6%\n",
      "Best validation: Loss=0.04, Accuracy=35.6%\n",
      "Loss=1.13, Accuracy=0.0% Loss=0.78, Accuracy=35.6%\n"
     ]
    }
   ],
   "source": [
    "model = ClassicDense(layer_sizes=[4, 8, 8, 3])\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "pre_loss, pre_acc = test(model, xts, yts)\n",
    "train_epochs(model, xtr, ytr, xts, yts, n_epochs=200, verbose=True)\n",
    "post_loss, post_acc = test(model, xts, yts)\n",
    "print(format_stats(pre_loss, pre_acc), format_stats(post_loss, post_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMeUQW+E3kItOSF30E4RKPD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
