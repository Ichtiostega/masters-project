{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 2582,
     "status": "ok",
     "timestamp": 1689624100162,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "bFBRtueF5TFK"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1689624100163,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "qdDI2BiZYRO7"
   },
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X = data['data']\n",
    "y = [[t] for t in data['target']]\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(y)\n",
    "y = ohe.transform(y)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1689624100163,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "PsGaNpbjZQoY"
   },
   "outputs": [],
   "source": [
    "xtr, xts, ytr, yts = train_test_split(X, y, train_size=0.7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1689624100163,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "Ba6Fw5YlZSqW"
   },
   "outputs": [],
   "source": [
    "class ClassicDense(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super().__init__()\n",
    "        input, output = layer_sizes[0], layer_sizes[-1]\n",
    "        self.hidden = nn.ModuleList([nn.Linear(layer_sizes[i], layer_sizes[i+1]) for i in range(len(layer_sizes)-2)])\n",
    "        self.act = nn.ModuleList([nn.ReLU() for i in range(len(layer_sizes)-2)])\n",
    "        self.output = nn.Linear(layer_sizes[-2], layer_sizes[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for hidden, act in zip(self.hidden, self.act):\n",
    "            x = act(hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1689624100164,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "Dmc03rnoZY2m"
   },
   "outputs": [],
   "source": [
    "def get_batched(data, batch_size):\n",
    "    if batch_size is None:\n",
    "        return data\n",
    "    dc = deepcopy(data)\n",
    "    while dc.numel():\n",
    "        batch, dc = dc[:batch_size], dc[batch_size:]\n",
    "        yield batch\n",
    "\n",
    "def format_stats(loss, acc):\n",
    "    return f\"Loss={loss:.2f}, Accuracy={acc*100:.1f}%\"\n",
    "        \n",
    "def train(model, xtr, ytr, batch_size = None):\n",
    "    cum_loss, cum_acc = [], []\n",
    "    for xtrb, ytrb in zip(get_batched(xtr, batch_size), get_batched(ytr, batch_size)):\n",
    "        ypred = model(xtrb)\n",
    "        loss = loss_fn(ypred, ytrb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = (torch.argmax(ypred, 1) == torch.argmax(ytrb, 1)).float().mean()\n",
    "        cum_loss.append(float(loss))\n",
    "        cum_acc.append(float(acc))\n",
    "    return cum_loss, cum_acc\n",
    "\n",
    "def test(model, xts, yts):\n",
    "    ypred = model(xts)\n",
    "    loss = loss_fn(ypred, yts)\n",
    "    acc = (torch.argmax(ypred, 1) == torch.argmax(xts, 1)).float().mean()\n",
    "    return float(loss), float(acc)\n",
    "\n",
    "\n",
    "def train_epochs(model, xtr, ytr, xts, yts, n_epochs = 100, batch_size = 5):\n",
    "    best_acc = - np.inf\n",
    "    best_weights = None\n",
    "    train_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = []\n",
    "        epoch_acc = []\n",
    "        model.train()\n",
    "        cum_loss, cum_acc = train(model, xtr, ytr, batch_size)\n",
    "        model.eval()\n",
    "        mloss, macc = np.mean(cum_loss), np.mean(cum_acc)\n",
    "        train_loss_hist.append(mloss)\n",
    "        train_acc_hist.append(macc)\n",
    "        if macc > best_acc:\n",
    "            best_acc = macc\n",
    "            best_weights = deepcopy(model.state_dict())\n",
    "        # print(f\"Epoch {epoch} validation: Cross-entropy={mloss:.2f}, Accuracy={macc*100:.1f}%\")\n",
    "    model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28911,
     "status": "ok",
     "timestamp": 1689624129897,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "FL7SQMQHX7uV",
    "outputId": "73259caf-dbc9-4530-d44b-9e5d3820d427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassicDense(\n",
      "  (hidden): ModuleList(\n",
      "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "  )\n",
      "  (act): ModuleList(\n",
      "    (0): ReLU()\n",
      "  )\n",
      "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n",
      "Loss=1.10, Accuracy=0.0% Loss=0.34, Accuracy=31.1%\n",
      "ClassicDense(\n",
      "  (hidden): ModuleList(\n",
      "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (1): Linear(in_features=8, out_features=8, bias=True)\n",
      "  )\n",
      "  (act): ModuleList(\n",
      "    (0-1): 2 x ReLU()\n",
      "  )\n",
      "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n",
      "Loss=1.04, Accuracy=0.0% Loss=0.43, Accuracy=31.1%\n",
      "ClassicDense(\n",
      "  (hidden): ModuleList(\n",
      "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (1): Linear(in_features=8, out_features=16, bias=True)\n",
      "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (act): ModuleList(\n",
      "    (0-2): 3 x ReLU()\n",
      "  )\n",
      "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n",
      "Loss=1.07, Accuracy=0.0% Loss=0.15, Accuracy=31.1%\n"
     ]
    }
   ],
   "source": [
    "model = ClassicDense(layer_sizes=[4,8,3])\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "pre_loss, pre_acc = test(model, xts, yts)\n",
    "train_epochs(model, xtr, ytr, xts, yts)\n",
    "post_loss, post_acc = test(model, xts, yts)\n",
    "print(format_stats(pre_loss, pre_acc), format_stats(post_loss, post_acc))\n",
    "\n",
    "model = ClassicDense(layer_sizes=[4,8,8,3])\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "pre_loss, pre_acc = test(model, xts, yts)\n",
    "train_epochs(model, xtr, ytr, xts, yts)\n",
    "post_loss, post_acc = test(model, xts, yts)\n",
    "print(format_stats(pre_loss, pre_acc), format_stats(post_loss, post_acc))\n",
    "\n",
    "model = ClassicDense(layer_sizes=[4,8,16,8,3])\n",
    "print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "pre_loss, pre_acc = test(model, xts, yts)\n",
    "train_epochs(model, xtr, ytr, xts, yts)\n",
    "post_loss, post_acc = test(model, xts, yts)\n",
    "print(format_stats(pre_loss, pre_acc), format_stats(post_loss, post_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1689622710529,
     "user": {
      "displayName": "Karol Kocierz",
      "userId": "17895505934666913437"
     },
     "user_tz": -120
    },
    "id": "TIqG-m9ULYQi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMeUQW+E3kItOSF30E4RKPD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
